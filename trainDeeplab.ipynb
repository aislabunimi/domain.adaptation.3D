{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd646f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanpath=\"/home/michele/Desktop/Colombo/Scannet/scans/scene0002_00/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your mapping file (tab-separated)\n",
    "df = pd.read_csv(scanpath+\"scannetv2-labels.combined.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Create id to class name mapping (e.g., from `id` to `nyuClass` or `category`)\n",
    "id_to_name = dict(zip(df[\"nyu40id\"], df[\"nyuClass\"]))  # or \"nyuClass\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f8c50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3dd749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Unknown\n",
      "Class 1: wall\n",
      "Class 2: floor\n",
      "Class 3: cabinet\n",
      "Class 5: chair\n",
      "Class 6: sofa\n",
      "Class 8: door\n",
      "Class 18: pillow\n",
      "Class 39: nan\n",
      "Class 40: cup\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "label = imageio.v2.imread(scanpath+\"label_nyu40/0.png\")\n",
    "\n",
    "# Get unique class IDs in the label image\n",
    "unique_classes = set(label.flatten())\n",
    "\n",
    "for cls_id in sorted(unique_classes):\n",
    "    print(f\"Class {cls_id}: {id_to_name.get(cls_id, 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3f71c",
   "metadata": {},
   "source": [
    "# Creating folder structure for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67fdf257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split complete! 5193 files -> 3635 train, 1038 val, 520 test.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "rgb_dir=scanpath+\"color\"         # Folder with .jpg images\n",
    "label_dir=scanpath+\"label_nyu40\"     # Folder with .png grayscale masks\n",
    "output_dir=\"output_db\"         # Output dataset folder\n",
    "train_pct=0.7\n",
    "val_pct=0.2\n",
    "test_pct=0.1\n",
    "\n",
    "\n",
    "rgb_dir = Path(rgb_dir)\n",
    "label_dir = Path(label_dir)\n",
    "output_dir = Path(output_dir)\n",
    "\n",
    "# Get matching image/label file names\n",
    "image_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith(\".jpg\")])\n",
    "label_files = sorted([f for f in os.listdir(label_dir) if f.endswith(\".png\")])\n",
    "\n",
    "assert len(image_files) == len(label_files), \"Number of images and labels must match\"\n",
    "assert all(os.path.splitext(i)[0] == os.path.splitext(l)[0] for i, l in zip(image_files, label_files)), \"Filenames don't match\"\n",
    "\n",
    "# Shuffle consistently\n",
    "paired = list(zip(image_files, label_files))\n",
    "random.shuffle(paired)\n",
    "\n",
    "n_total = len(paired)\n",
    "n_train = int(train_pct * n_total)\n",
    "n_val = int(val_pct * n_total)\n",
    "\n",
    "train_set = paired[:n_train]\n",
    "val_set = paired[n_train:n_train+n_val]\n",
    "test_set = paired[n_train+n_val:]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_set,\n",
    "    \"val\": val_set,\n",
    "    \"test\": test_set\n",
    "}\n",
    "\n",
    "# Create directory structure\n",
    "for subfolder in [\"images\", \"labels\"]:\n",
    "    for split in splits:\n",
    "        path = output_dir / subfolder / split\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy files\n",
    "for split, items in splits.items():\n",
    "    for img_name, lbl_name in items:\n",
    "        shutil.copy(rgb_dir / img_name, output_dir / \"images\" / split / img_name)\n",
    "        shutil.copy(label_dir / lbl_name, output_dir / \"labels\" / split / lbl_name)\n",
    "\n",
    "print(f\"‚úÖ Split complete! {n_total} files -> {n_train} train, {n_val} val, {len(test_set)} test.\")\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864e286",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cbda54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.9.0+cu111\n",
      "CUDA disponibile: True\n",
      "Versione CUDA supportata da PyTorch: 11.1\n",
      "Numero di GPU: 1\n",
      "Nome GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "Dispositivo corrente: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA disponibile:\", torch.cuda.is_available())\n",
    "print(\"Versione CUDA supportata da PyTorch:\", torch.version.cuda)\n",
    "print(\"Numero di GPU:\", torch.cuda.device_count())\n",
    "print(\"Nome GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nessuna GPU trovata\")\n",
    "print(\"Dispositivo corrente:\", torch.cuda.current_device() if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6979c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()       # Clears unused memory from the GPU cache\n",
    "torch.cuda.ipc_collect()       # Collects inter-process memory (useful if you're restarting processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad794c7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.94 GiB total capacity; 2.66 GiB already allocated; 29.00 MiB free; 2.67 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m model \u001b[38;5;241m=\u001b[39m deeplabv3_resnet50(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m256\u001b[39m, NUM_CLASSES, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# ==== Loss and Optimizer ====\u001b[39;00m\n\u001b[1;32m     67\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/habitat/lib/python3.9/site-packages/torch/nn/modules/module.py:637\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/habitat/lib/python3.9/site-packages/torch/nn/modules/module.py:530\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 530\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/habitat/lib/python3.9/site-packages/torch/nn/modules/module.py:530\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 530\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 530 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/habitat/lib/python3.9/site-packages/torch/nn/modules/module.py:530\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 530\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/habitat/lib/python3.9/site-packages/torch/nn/modules/module.py:552\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 552\u001b[0m         param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/habitat/lib/python3.9/site-packages/torch/nn/modules/module.py:637\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.94 GiB total capacity; 2.66 GiB already allocated; 29.00 MiB free; 2.67 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Config Parameters ====\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 4\n",
    "PATIENCE = 5\n",
    "IMAGE_SIZE =  (480, 640)  # (Height, Width)\n",
    "\n",
    "# ==== Custom Dataset ====\n",
    "class NYU40SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.label_dir = Path(label_dir)\n",
    "        self.images = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])\n",
    "        self.labels = sorted([f for f in os.listdir(label_dir) if f.endswith(\".png\")])\n",
    "        self.transform = transform\n",
    "\n",
    "        assert len(self.images) == len(self.labels), \"Mismatch in image and label count\"\n",
    "        assert all(os.path.splitext(i)[0] == os.path.splitext(l)[0] for i, l in zip(self.images, self.labels)), \"Mismatch in filenames\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_dir / self.images[idx]\n",
    "        label_path = self.label_dir / self.labels[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        label = Image.open(label_path)\n",
    "\n",
    "        image = self.transform(image) if self.transform else T.ToTensor()(image)\n",
    "        label = torch.from_numpy(np.array(label)).long()\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# ==== Transforms ====\n",
    "transform = T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# ==== Paths ====\n",
    "root = Path(\"output_db\")\n",
    "train_dataset = NYU40SegmentationDataset(root / \"images/train\", root / \"labels/train\", transform)\n",
    "val_dataset   = NYU40SegmentationDataset(root / \"images/val\", root / \"labels/val\", transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ==== Model ====\n",
    "NUM_CLASSES = 40  # NYU40\n",
    "model = deeplabv3_resnet50(pretrained=True)\n",
    "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "model = model.cuda()\n",
    "\n",
    "# ==== Loss and Optimizer ====\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ==== Training with Early Stopping ====\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, labels in tqdm(train_loader, desc=f\"[Train] Epoch {epoch+1}\"):\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        outputs = model(imgs)['out']\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"‚úÖ Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            outputs = model(imgs)['out']\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"üîç Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"deeplabv3_nyu40.pth\")\n",
    "        print(\"üíæ Model improved. Saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚ö†Ô∏è No improvement. Patience: {patience_counter}/{PATIENCE}\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"‚úÖ Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# Load the test set\n",
    "test_dataset = NYU40SegmentationDataset(root / \"images/test\", root / \"labels/test\", transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Put the model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Inference loop\n",
    "with torch.no_grad():\n",
    "    for idx, (img, label) in enumerate(test_loader):\n",
    "        img = img.cuda()\n",
    "        output = model(img)['out']\n",
    "        pred = torch.argmax(output.squeeze(), dim=0).detach().cpu().numpy()\n",
    "\n",
    "        # Save or visualize the prediction\n",
    "        pred_image = Image.fromarray(pred.astype(np.uint8))\n",
    "        pred_image.save(f\"predictions/test_{idx}.png\")\n",
    "\n",
    "        # Optional: save original RGB for comparison\n",
    "        TF.to_pil_image(img.cpu().squeeze()).save(f\"predictions/test_{idx}_rgb.jpg\")\n",
    "\n",
    "        if idx < 5:  # display a few examples\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.imshow(TF.to_pil_image(img.cpu().squeeze()))\n",
    "            plt.title(\"RGB\")\n",
    "\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.imshow(label.squeeze().cpu(), cmap=\"gray\")\n",
    "            plt.title(\"Ground Truth\")\n",
    "\n",
    "            plt.subplot(1,3,3)\n",
    "            plt.imshow(pred, cmap=\"gray\")\n",
    "            plt.title(\"Prediction\")\n",
    "\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
